{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK8ea7hr2qYT",
        "outputId": "105e8d6a-1756-4ca8-b45e-eedd3a2e6d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded sucessfully\n",
            "\n",
            "Top 5 rows of the dataset: \n",
            "    Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "Bottom 5 rows of the dataset: \n",
            "      Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "\n",
            "Information of the dataset: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "\n",
            "Descriptive info about the dataset: \n",
            "               Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n",
            "\n",
            "Features(X): \n",
            "    Reading  Writing\n",
            "0       68       63\n",
            "1       81       72\n",
            "2       80       78\n",
            "3       83       79\n",
            "4       64       62\n",
            "\n",
            "Target(Y): \n",
            "    Math\n",
            "0    48\n",
            "1    62\n",
            "2    79\n",
            "3    76\n",
            "4    59\n"
          ]
        }
      ],
      "source": [
        "#Implementation from Scratch\n",
        "# To - Do - 1:\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Concepts of AI/Datasets/student.csv\")\n",
        "\n",
        "# 1\n",
        "print(\"Dataset loaded sucessfully\\n\")\n",
        "\n",
        "# 2\n",
        "print(\"Top 5 rows of the dataset: \\n\",data.head())\n",
        "print(\"Bottom 5 rows of the dataset: \\n\",data.tail())\n",
        "\n",
        "# 3\n",
        "print(\"\\nInformation of the dataset: \")\n",
        "data.info()\n",
        "\n",
        "# 4\n",
        "print(\"\\nDescriptive info about the dataset: \\n\",data.describe())\n",
        "\n",
        "# 5\n",
        "X = data[[\"Reading\", \"Writing\"]]\n",
        "Y = data[[\"Math\"]]\n",
        "print(\"\\nFeatures(X): \\n\",X.head())\n",
        "print(\"\\nTarget(Y): \\n\",Y.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To - Do - 2:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Concepts of AI/Datasets/student.csv\")\n",
        "\n",
        "X = data[[\"Math\"]].to_numpy().T\n",
        "\n",
        "d = X.shape[0]\n",
        "W = np.random.rand(d, 1)\n",
        "\n",
        "Y = np.dot(W.T, X)\n",
        "\n",
        "print(\"Feature Matrix (X):\")\n",
        "print(X)\n",
        "\n",
        "print(\"\\nWeight Matrix (W):\")\n",
        "print(W)\n",
        "\n",
        "print(\"\\nOutput Matrix (Y):\")\n",
        "print(Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnc9xiCFBUXh",
        "outputId": "5bb19d05-ca58-47e1-fea1-06c3196172c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Matrix (X):\n",
            "[[ 48  62  79  76  59  69  70  46  61  86  62  72  56  81  61  49  60  45\n",
            "   71  75  66  57  67  63  68  68  62  56  82  64  71  69  64  76  61  47\n",
            "   50  75  69  42  73  78  65  51  61  69  51  64  90  58 100  73  62  45\n",
            "   47  53  62  49  77  70  60  82 100  72  62  87  56  96  68  66  68  59\n",
            "   52  60  60  46  62  30  83  69  82  64  57  71  37  69  72  73  70  75\n",
            "   54  71  60  81  58  54  49  64  84  84  33  51  68  32  43  73  82  47\n",
            "   74  36  58  68  92  75  43  68  49  69  91  83  65  79  74  81  41  48\n",
            "   31  53  87  94  77  57  64  55  61  78  94  88  77  90  55  83  68  66\n",
            "   56  65  84  90  80  47  67  79  68  62  62  44  74  67  46  71  73  49\n",
            "   42  55  73  75  96  66  56 100  53  68  72  55  59  76  84  68  61  53\n",
            "   73  61  73  63  51  70  69  61  88  90  60 100  68  85  41  70  91  68\n",
            "   63  81  89  66  59  80  87  30  63  43  73  49  65  72  83  46  65 100\n",
            "   40  73  58  87  61  71  72  81  67  69  53  70  56  84  44  63  82  61\n",
            "   68  75  78  32  62  84  65  41  57  54  58  68  53  30  63  36  85  66\n",
            "   45  69  71  70  31  61  73  66  63  64  63  19  64  96  59  59  75  51\n",
            "  100  45  67  34  82  62  59  84  80  65  71  35  46  72  70  80  72  61\n",
            "   39  53  80  73  68  73  57  56  46  48  78  62  89  89  65  49  65  71\n",
            "   70  48  75  83  51  77  51  79  73  72  68  74  58  70  52  70  71  79\n",
            "   71  73  89  54  90  88  72  69  61  46  98  47  71  70  83  51  85  56\n",
            "   98  53  47  86  93  62  66  79  56  41  79  70  89  33  78  77  58  66\n",
            "   72  94  58  55  65  72  46  76  67  71  88  72  66  79  73  49  58  72\n",
            "   78  95  87  95  64  71  80  72  64  46  63  83  61  60  47  82  59  49\n",
            "   80  61  72  64  92  59  69  54  74  78  69  57  55  63  89 100  60  76\n",
            "   73  64  40  79  90  71  47  48  78  55  76  91  39  35  60  89  82  44\n",
            "   89  87  45  66  81  79  71  43  79  81  64  91  62  78  90  46  81  65\n",
            "   58  73  73  58  46  77  42  82  64  87  60  33  60  56  73  64  64  81\n",
            "   60  79  76  83  65  76  78  71  73  67  64  48  82  58  74  71  60  81\n",
            "   47  76  55  80  79  59  62  86  89  53  70  71  56  54  64  44  61  52\n",
            "   56  70  69  74  73  71  82  59  50  38  81  39  68  40  80  59  78  63\n",
            "   71  79  42  67  76  84  74  59  57  55  55  32  95  62  72  51  46  84\n",
            "   68  43  73  79  81  66  93  82  78  71  67  51  89  56  67  62  72  81\n",
            "   67  49  64  81  99  51  78  76  64  90  67  76  43  63  82  72  69  54\n",
            "   54  59  66  77  70  61  75  52  77  73  55  75  45  67  57 100  67  78\n",
            "   56  57  83  89 100  75  60  73  81  91  61  59  65  57  57  76  77  91\n",
            "   68 100  57  78  80  42  66  60  67  40  64  56  61  76  90  80  72  68\n",
            "   40  79  77  83  96 100  72  79  80  67  53  66  91  52  97  63  69  65\n",
            "   65  84  79  73  92  60  84  82  44  90  69  72  69  57  93  69  75  45\n",
            "   46  90  66  57  65  87  39  87  77  57  59  74  60  75  95  74  53  56\n",
            "   91  74  47  95  49  66 100  33  99  39  56  36  58  52  59  67  55  40\n",
            "   32  91  31  54  69  55  73  98  60  26  95  76  53  67  80  76  74  67\n",
            "   81  95  58  80  83  52  69  59  62  70  65  61  42  69  76  83  62  42\n",
            "   64  61  69  77  80  93  63 100  88  76  72  84  86  59  77  53  87  72\n",
            "   67  65  84  77  77  77  45  61  61  62  68  62  49  13  55  85  78  69\n",
            "   69  45  67  68  81  73  53  80  56  82  69  76  44  25  82  55  65  79\n",
            "   95  62  80  93  57  54 100  67  47  69  84  50  79  50  48  56  72  47\n",
            "   68  79  74  37  73  92  75  61  56  52  96  59  67  89  50  51  76  80\n",
            "   68  46 100  44  48  67  88  74  82  77  56  96  67  60  63  77  50  44\n",
            "   64  50  82  91  31  67  90  89  61  64  69  78  58  68  64  85  68  63\n",
            "   68  34  77  61  53  80  62  79  83  65  58  73  94  86  76  58  61  58\n",
            "   64  51  82  56  65  76  48  85  68  85  62  75  38  63  68  62  73  65\n",
            "   77  63  83  55  87  95  48  36  84  91  79  51  76  82  71  52  60  64\n",
            "   68  37  67  51  78  75  60  67  51  78  64  59  85  74  40  94  58  68\n",
            "   83  83  68  74  85  65  68  75  52  74  60  51  64  76  45  55  45  86\n",
            "   85  58  72  59  60  70  79  77  77  66  68  65  70  70  55  81  62  81\n",
            "   71  42  62  57  80  78  71  86  76  45  71  64  69  84  65  55  64  84\n",
            "   52  67  77  64  58  72  73  89  83  66]]\n",
            "\n",
            "Weight Matrix (W):\n",
            "[[0.80692361]]\n",
            "\n",
            "Output Matrix (Y):\n",
            "[[38.73233337 50.02926394 63.74696534 61.3261945  47.6084931  55.67772922\n",
            "  56.48465283 37.11848615 49.22234032 69.39543062 50.02926394 58.09850006\n",
            "  45.18772227 65.36081256 49.22234032 39.53925698 48.41541671 36.31156253\n",
            "  57.29157644 60.51927089 53.25695838 45.99464588 54.063882   50.83618755\n",
            "  54.87080561 54.87080561 50.02926394 45.18772227 66.16773617 51.64311116\n",
            "  57.29157644 55.67772922 51.64311116 61.3261945  49.22234032 37.92540976\n",
            "  40.34618059 60.51927089 55.67772922 33.8907917  58.90542367 62.94004173\n",
            "  52.45003477 41.15310421 49.22234032 55.67772922 41.15310421 51.64311116\n",
            "  72.62312507 46.80156949 80.69236119 58.90542367 50.02926394 36.31156253\n",
            "  37.92540976 42.76695143 50.02926394 39.53925698 62.13311811 56.48465283\n",
            "  48.41541671 66.16773617 80.69236119 58.09850006 50.02926394 70.20235423\n",
            "  45.18772227 77.46466674 54.87080561 53.25695838 54.87080561 47.6084931\n",
            "  41.96002782 48.41541671 48.41541671 37.11848615 50.02926394 24.20770836\n",
            "  66.97465979 55.67772922 66.16773617 51.64311116 45.99464588 57.29157644\n",
            "  29.85617364 55.67772922 58.09850006 58.90542367 56.48465283 60.51927089\n",
            "  43.57387504 57.29157644 48.41541671 65.36081256 46.80156949 43.57387504\n",
            "  39.53925698 51.64311116 67.7815834  67.7815834  26.62847919 41.15310421\n",
            "  54.87080561 25.82155558 34.69771531 58.90542367 66.16773617 37.92540976\n",
            "  59.71234728 29.04925003 46.80156949 54.87080561 74.23697229 60.51927089\n",
            "  34.69771531 54.87080561 39.53925698 55.67772922 73.43004868 66.97465979\n",
            "  52.45003477 63.74696534 59.71234728 65.36081256 33.08386809 38.73233337\n",
            "  25.01463197 42.76695143 70.20235423 75.85081952 62.13311811 45.99464588\n",
            "  51.64311116 44.38079865 49.22234032 62.94004173 75.85081952 71.00927785\n",
            "  62.13311811 72.62312507 44.38079865 66.97465979 54.87080561 53.25695838\n",
            "  45.18772227 52.45003477 67.7815834  72.62312507 64.55388895 37.92540976\n",
            "  54.063882   63.74696534 54.87080561 50.02926394 50.02926394 35.50463892\n",
            "  59.71234728 54.063882   37.11848615 57.29157644 58.90542367 39.53925698\n",
            "  33.8907917  44.38079865 58.90542367 60.51927089 77.46466674 53.25695838\n",
            "  45.18772227 80.69236119 42.76695143 54.87080561 58.09850006 44.38079865\n",
            "  47.6084931  61.3261945  67.7815834  54.87080561 49.22234032 42.76695143\n",
            "  58.90542367 49.22234032 58.90542367 50.83618755 41.15310421 56.48465283\n",
            "  55.67772922 49.22234032 71.00927785 72.62312507 48.41541671 80.69236119\n",
            "  54.87080561 68.58850701 33.08386809 56.48465283 73.43004868 54.87080561\n",
            "  50.83618755 65.36081256 71.81620146 53.25695838 47.6084931  64.55388895\n",
            "  70.20235423 24.20770836 50.83618755 34.69771531 58.90542367 39.53925698\n",
            "  52.45003477 58.09850006 66.97465979 37.11848615 52.45003477 80.69236119\n",
            "  32.27694448 58.90542367 46.80156949 70.20235423 49.22234032 57.29157644\n",
            "  58.09850006 65.36081256 54.063882   55.67772922 42.76695143 56.48465283\n",
            "  45.18772227 67.7815834  35.50463892 50.83618755 66.16773617 49.22234032\n",
            "  54.87080561 60.51927089 62.94004173 25.82155558 50.02926394 67.7815834\n",
            "  52.45003477 33.08386809 45.99464588 43.57387504 46.80156949 54.87080561\n",
            "  42.76695143 24.20770836 50.83618755 29.04925003 68.58850701 53.25695838\n",
            "  36.31156253 55.67772922 57.29157644 56.48465283 25.01463197 49.22234032\n",
            "  58.90542367 53.25695838 50.83618755 51.64311116 50.83618755 15.33154863\n",
            "  51.64311116 77.46466674 47.6084931  47.6084931  60.51927089 41.15310421\n",
            "  80.69236119 36.31156253 54.063882   27.4354028  66.16773617 50.02926394\n",
            "  47.6084931  67.7815834  64.55388895 52.45003477 57.29157644 28.24232642\n",
            "  37.11848615 58.09850006 56.48465283 64.55388895 58.09850006 49.22234032\n",
            "  31.47002086 42.76695143 64.55388895 58.90542367 54.87080561 58.90542367\n",
            "  45.99464588 45.18772227 37.11848615 38.73233337 62.94004173 50.02926394\n",
            "  71.81620146 71.81620146 52.45003477 39.53925698 52.45003477 57.29157644\n",
            "  56.48465283 38.73233337 60.51927089 66.97465979 41.15310421 62.13311811\n",
            "  41.15310421 63.74696534 58.90542367 58.09850006 54.87080561 59.71234728\n",
            "  46.80156949 56.48465283 41.96002782 56.48465283 57.29157644 63.74696534\n",
            "  57.29157644 58.90542367 71.81620146 43.57387504 72.62312507 71.00927785\n",
            "  58.09850006 55.67772922 49.22234032 37.11848615 79.07851396 37.92540976\n",
            "  57.29157644 56.48465283 66.97465979 41.15310421 68.58850701 45.18772227\n",
            "  79.07851396 42.76695143 37.92540976 69.39543062 75.0438959  50.02926394\n",
            "  53.25695838 63.74696534 45.18772227 33.08386809 63.74696534 56.48465283\n",
            "  71.81620146 26.62847919 62.94004173 62.13311811 46.80156949 53.25695838\n",
            "  58.09850006 75.85081952 46.80156949 44.38079865 52.45003477 58.09850006\n",
            "  37.11848615 61.3261945  54.063882   57.29157644 71.00927785 58.09850006\n",
            "  53.25695838 63.74696534 58.90542367 39.53925698 46.80156949 58.09850006\n",
            "  62.94004173 76.65774313 70.20235423 76.65774313 51.64311116 57.29157644\n",
            "  64.55388895 58.09850006 51.64311116 37.11848615 50.83618755 66.97465979\n",
            "  49.22234032 48.41541671 37.92540976 66.16773617 47.6084931  39.53925698\n",
            "  64.55388895 49.22234032 58.09850006 51.64311116 74.23697229 47.6084931\n",
            "  55.67772922 43.57387504 59.71234728 62.94004173 55.67772922 45.99464588\n",
            "  44.38079865 50.83618755 71.81620146 80.69236119 48.41541671 61.3261945\n",
            "  58.90542367 51.64311116 32.27694448 63.74696534 72.62312507 57.29157644\n",
            "  37.92540976 38.73233337 62.94004173 44.38079865 61.3261945  73.43004868\n",
            "  31.47002086 28.24232642 48.41541671 71.81620146 66.16773617 35.50463892\n",
            "  71.81620146 70.20235423 36.31156253 53.25695838 65.36081256 63.74696534\n",
            "  57.29157644 34.69771531 63.74696534 65.36081256 51.64311116 73.43004868\n",
            "  50.02926394 62.94004173 72.62312507 37.11848615 65.36081256 52.45003477\n",
            "  46.80156949 58.90542367 58.90542367 46.80156949 37.11848615 62.13311811\n",
            "  33.8907917  66.16773617 51.64311116 70.20235423 48.41541671 26.62847919\n",
            "  48.41541671 45.18772227 58.90542367 51.64311116 51.64311116 65.36081256\n",
            "  48.41541671 63.74696534 61.3261945  66.97465979 52.45003477 61.3261945\n",
            "  62.94004173 57.29157644 58.90542367 54.063882   51.64311116 38.73233337\n",
            "  66.16773617 46.80156949 59.71234728 57.29157644 48.41541671 65.36081256\n",
            "  37.92540976 61.3261945  44.38079865 64.55388895 63.74696534 47.6084931\n",
            "  50.02926394 69.39543062 71.81620146 42.76695143 56.48465283 57.29157644\n",
            "  45.18772227 43.57387504 51.64311116 35.50463892 49.22234032 41.96002782\n",
            "  45.18772227 56.48465283 55.67772922 59.71234728 58.90542367 57.29157644\n",
            "  66.16773617 47.6084931  40.34618059 30.66309725 65.36081256 31.47002086\n",
            "  54.87080561 32.27694448 64.55388895 47.6084931  62.94004173 50.83618755\n",
            "  57.29157644 63.74696534 33.8907917  54.063882   61.3261945  67.7815834\n",
            "  59.71234728 47.6084931  45.99464588 44.38079865 44.38079865 25.82155558\n",
            "  76.65774313 50.02926394 58.09850006 41.15310421 37.11848615 67.7815834\n",
            "  54.87080561 34.69771531 58.90542367 63.74696534 65.36081256 53.25695838\n",
            "  75.0438959  66.16773617 62.94004173 57.29157644 54.063882   41.15310421\n",
            "  71.81620146 45.18772227 54.063882   50.02926394 58.09850006 65.36081256\n",
            "  54.063882   39.53925698 51.64311116 65.36081256 79.88543758 41.15310421\n",
            "  62.94004173 61.3261945  51.64311116 72.62312507 54.063882   61.3261945\n",
            "  34.69771531 50.83618755 66.16773617 58.09850006 55.67772922 43.57387504\n",
            "  43.57387504 47.6084931  53.25695838 62.13311811 56.48465283 49.22234032\n",
            "  60.51927089 41.96002782 62.13311811 58.90542367 44.38079865 60.51927089\n",
            "  36.31156253 54.063882   45.99464588 80.69236119 54.063882   62.94004173\n",
            "  45.18772227 45.99464588 66.97465979 71.81620146 80.69236119 60.51927089\n",
            "  48.41541671 58.90542367 65.36081256 73.43004868 49.22234032 47.6084931\n",
            "  52.45003477 45.99464588 45.99464588 61.3261945  62.13311811 73.43004868\n",
            "  54.87080561 80.69236119 45.99464588 62.94004173 64.55388895 33.8907917\n",
            "  53.25695838 48.41541671 54.063882   32.27694448 51.64311116 45.18772227\n",
            "  49.22234032 61.3261945  72.62312507 64.55388895 58.09850006 54.87080561\n",
            "  32.27694448 63.74696534 62.13311811 66.97465979 77.46466674 80.69236119\n",
            "  58.09850006 63.74696534 64.55388895 54.063882   42.76695143 53.25695838\n",
            "  73.43004868 41.96002782 78.27159035 50.83618755 55.67772922 52.45003477\n",
            "  52.45003477 67.7815834  63.74696534 58.90542367 74.23697229 48.41541671\n",
            "  67.7815834  66.16773617 35.50463892 72.62312507 55.67772922 58.09850006\n",
            "  55.67772922 45.99464588 75.0438959  55.67772922 60.51927089 36.31156253\n",
            "  37.11848615 72.62312507 53.25695838 45.99464588 52.45003477 70.20235423\n",
            "  31.47002086 70.20235423 62.13311811 45.99464588 47.6084931  59.71234728\n",
            "  48.41541671 60.51927089 76.65774313 59.71234728 42.76695143 45.18772227\n",
            "  73.43004868 59.71234728 37.92540976 76.65774313 39.53925698 53.25695838\n",
            "  80.69236119 26.62847919 79.88543758 31.47002086 45.18772227 29.04925003\n",
            "  46.80156949 41.96002782 47.6084931  54.063882   44.38079865 32.27694448\n",
            "  25.82155558 73.43004868 25.01463197 43.57387504 55.67772922 44.38079865\n",
            "  58.90542367 79.07851396 48.41541671 20.98001391 76.65774313 61.3261945\n",
            "  42.76695143 54.063882   64.55388895 61.3261945  59.71234728 54.063882\n",
            "  65.36081256 76.65774313 46.80156949 64.55388895 66.97465979 41.96002782\n",
            "  55.67772922 47.6084931  50.02926394 56.48465283 52.45003477 49.22234032\n",
            "  33.8907917  55.67772922 61.3261945  66.97465979 50.02926394 33.8907917\n",
            "  51.64311116 49.22234032 55.67772922 62.13311811 64.55388895 75.0438959\n",
            "  50.83618755 80.69236119 71.00927785 61.3261945  58.09850006 67.7815834\n",
            "  69.39543062 47.6084931  62.13311811 42.76695143 70.20235423 58.09850006\n",
            "  54.063882   52.45003477 67.7815834  62.13311811 62.13311811 62.13311811\n",
            "  36.31156253 49.22234032 49.22234032 50.02926394 54.87080561 50.02926394\n",
            "  39.53925698 10.49000695 44.38079865 68.58850701 62.94004173 55.67772922\n",
            "  55.67772922 36.31156253 54.063882   54.87080561 65.36081256 58.90542367\n",
            "  42.76695143 64.55388895 45.18772227 66.16773617 55.67772922 61.3261945\n",
            "  35.50463892 20.1730903  66.16773617 44.38079865 52.45003477 63.74696534\n",
            "  76.65774313 50.02926394 64.55388895 75.0438959  45.99464588 43.57387504\n",
            "  80.69236119 54.063882   37.92540976 55.67772922 67.7815834  40.34618059\n",
            "  63.74696534 40.34618059 38.73233337 45.18772227 58.09850006 37.92540976\n",
            "  54.87080561 63.74696534 59.71234728 29.85617364 58.90542367 74.23697229\n",
            "  60.51927089 49.22234032 45.18772227 41.96002782 77.46466674 47.6084931\n",
            "  54.063882   71.81620146 40.34618059 41.15310421 61.3261945  64.55388895\n",
            "  54.87080561 37.11848615 80.69236119 35.50463892 38.73233337 54.063882\n",
            "  71.00927785 59.71234728 66.16773617 62.13311811 45.18772227 77.46466674\n",
            "  54.063882   48.41541671 50.83618755 62.13311811 40.34618059 35.50463892\n",
            "  51.64311116 40.34618059 66.16773617 73.43004868 25.01463197 54.063882\n",
            "  72.62312507 71.81620146 49.22234032 51.64311116 55.67772922 62.94004173\n",
            "  46.80156949 54.87080561 51.64311116 68.58850701 54.87080561 50.83618755\n",
            "  54.87080561 27.4354028  62.13311811 49.22234032 42.76695143 64.55388895\n",
            "  50.02926394 63.74696534 66.97465979 52.45003477 46.80156949 58.90542367\n",
            "  75.85081952 69.39543062 61.3261945  46.80156949 49.22234032 46.80156949\n",
            "  51.64311116 41.15310421 66.16773617 45.18772227 52.45003477 61.3261945\n",
            "  38.73233337 68.58850701 54.87080561 68.58850701 50.02926394 60.51927089\n",
            "  30.66309725 50.83618755 54.87080561 50.02926394 58.90542367 52.45003477\n",
            "  62.13311811 50.83618755 66.97465979 44.38079865 70.20235423 76.65774313\n",
            "  38.73233337 29.04925003 67.7815834  73.43004868 63.74696534 41.15310421\n",
            "  61.3261945  66.16773617 57.29157644 41.96002782 48.41541671 51.64311116\n",
            "  54.87080561 29.85617364 54.063882   41.15310421 62.94004173 60.51927089\n",
            "  48.41541671 54.063882   41.15310421 62.94004173 51.64311116 47.6084931\n",
            "  68.58850701 59.71234728 32.27694448 75.85081952 46.80156949 54.87080561\n",
            "  66.97465979 66.97465979 54.87080561 59.71234728 68.58850701 52.45003477\n",
            "  54.87080561 60.51927089 41.96002782 59.71234728 48.41541671 41.15310421\n",
            "  51.64311116 61.3261945  36.31156253 44.38079865 36.31156253 69.39543062\n",
            "  68.58850701 46.80156949 58.09850006 47.6084931  48.41541671 56.48465283\n",
            "  63.74696534 62.13311811 62.13311811 53.25695838 54.87080561 52.45003477\n",
            "  56.48465283 56.48465283 44.38079865 65.36081256 50.02926394 65.36081256\n",
            "  57.29157644 33.8907917  50.02926394 45.99464588 64.55388895 62.94004173\n",
            "  57.29157644 69.39543062 61.3261945  36.31156253 57.29157644 51.64311116\n",
            "  55.67772922 67.7815834  52.45003477 44.38079865 51.64311116 67.7815834\n",
            "  41.96002782 54.063882   62.13311811 51.64311116 46.80156949 58.09850006\n",
            "  58.90542367 71.81620146 66.97465979 53.25695838]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To - Do - 3:\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Concepts of AI/Datasets/student.csv\")\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(data) * train_ratio)\n",
        "\n",
        "train_data = data.iloc[:train_size]\n",
        "test_data = data.iloc[train_size:]\n",
        "\n",
        "X_train = train_data.drop('Math', axis=1)\n",
        "y_train = train_data['Math']\n",
        "\n",
        "X_test = test_data.drop('Math', axis=1)\n",
        "y_test = test_data['Math']\n",
        "\n",
        "print(f\"Training data size: {len(X_train)}\")\n",
        "print(f\"Test data size: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9mhAEuICSu6",
        "outputId": "f0cb2a85-37d7-43e8-b381-06dee63ffd05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 800\n",
            "Test data size: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To - Do:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def gradient_descent(X, y, W, learning_rate, num_iterations):\n",
        "    m = len(y)\n",
        "    for _ in range(num_iterations):\n",
        "        predictions = X.dot(W)\n",
        "        errors = predictions - y\n",
        "        gradient = (1/m) * X.T.dot(errors)\n",
        "        W -= learning_rate * gradient\n",
        "    return W\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "def r2_score_custom(y_true, y_pred):\n",
        "    total_variance = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    unexplained_variance = np.sum((y_true - y_pred) ** 2)\n",
        "    return 1 - (unexplained_variance / total_variance)\n",
        "\n",
        "def train_and_evaluate_model(data, target_column, learning_rate=0.01, num_iterations=1000, train_ratio=0.8):\n",
        "    X = data.drop(target_column, axis=1).values\n",
        "    y = data[target_column].values.reshape(-1, 1)\n",
        "\n",
        "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "    X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "\n",
        "    train_size = int(len(data) * train_ratio)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    W = np.zeros((X_train.shape[1], 1))\n",
        "\n",
        "    W = gradient_descent(X_train, y_train, W, learning_rate, num_iterations)\n",
        "\n",
        "    y_pred = X_test.dot(W)\n",
        "\n",
        "    rmse_value = rmse(y_test, y_pred)\n",
        "    r2_value = r2_score_custom(y_test, y_pred)\n",
        "\n",
        "    print(f\"RMSE: {rmse_value}\")\n",
        "    print(f\"R²: {r2_value}\")\n",
        "\n",
        "    return W\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Concepts of AI/Datasets/student.csv\")\n",
        "\n",
        "W = train_and_evaluate_model(data, target_column='Math', learning_rate=0.01, num_iterations=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKwVDtyQGzAr",
        "outputId": "428c3c0a-e482-41f8-c936-5e9b0d5da654"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 8.063025179232353\n",
            "R²: 0.6688016401848758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With an R² of 0.67, the model seems to have moderate predictive power, meaning it is not perfect but still provides a reasonable fit to the data.\n",
        "\n",
        "The RMSE of 8.06 suggests that the model has a moderate error between predictions and actual values, but without knowing the scale of the target variable, it's difficult to say whether the error is large or acceptable.\n",
        "\n"
      ],
      "metadata": {
        "id": "n-zVt7RhHz8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different value of learning rate,\n",
        "learning_rates = [0.001, 0.01, 0.1, 0.5, 1]  # Different learning rates to experiment with\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"Evaluating model with learning rate: {lr}\")\n",
        "    W = train_and_evaluate_model(data, target_column='Math', learning_rate=lr, num_iterations=1000)\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n60exJvAIFSC",
        "outputId": "7b4820b7-24cc-4054-dc7a-19daf0f397b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model with learning rate: 0.001\n",
            "RMSE: 26.48769209042315\n",
            "R²: -2.574212619577433\n",
            "--------------------------------------------------\n",
            "Evaluating model with learning rate: 0.01\n",
            "RMSE: 8.063025179232353\n",
            "R²: 0.6688016401848758\n",
            "--------------------------------------------------\n",
            "Evaluating model with learning rate: 0.1\n",
            "RMSE: 8.055145895402044\n",
            "R²: 0.6694486258395718\n",
            "--------------------------------------------------\n",
            "Evaluating model with learning rate: 0.5\n",
            "RMSE: 8.055066650205903\n",
            "R²: 0.6694551296273297\n",
            "--------------------------------------------------\n",
            "Evaluating model with learning rate: 1\n",
            "RMSE: 694744374.0629731\n",
            "R²: -2458907675230898.0\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower Learning Rate (e.g., 0.001):\n",
        "Training will be slower, but it may converge more smoothly without overshooting.\n",
        "If the model performs poorly, it could be that it hasn't learned enough due to slow updates.\n",
        "\n",
        "Moderate Learning Rate (e.g., 0.01):\n",
        "A good balance between speed and convergence. This is often a reasonable starting point for many models.\n",
        "\n",
        "Higher Learning Rate (e.g., 0.1, 0.5, 1):\n",
        "The model may converge faster, but there’s a risk of overshooting the optimal weights.\n",
        "If the learning rate is too high, the model might fail to converge or result in large errors (high RMSE)."
      ],
      "metadata": {
        "id": "bgFiTPqKISfm"
      }
    }
  ]
}